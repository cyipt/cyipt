---
title: "Modelling Cycling Update"
author: "Robin Lovelace"
date: "8 May 2017"
output:
  github_document:
    toc: true
---

This document reports on methods and preliminary findings associated with the modelling of cycling uptake associated with infrastructure.

## Input data

The first stage is to load region-specific data.
Eventually these will cover any region, e.g. as specified by the region variable and selected from an appropriate data source:

```{r}
region_name = "avon"
data_source = "https://github.com/npct/pct-data/raw/master/"
```

For the case study region of Bristol, the data is stored in the `example-data` folder:

```{r, message=FALSE, results='hide'}
library(sf)
library(tidyverse)
region = st_read("areas/bristol-poly.geojson")
```

The input data comes from 3 main sources:


- Outputs from the PCT, which reports current cycling levels and estimated 'fastest routes' for cyclists. After combining the straight lines, quietest routes and fastest routes into a single list object, they can be loaded as follows:

```{r, echo=FALSE, eval=FALSE}
# Commented - no longer use this data source
if(!file.exists("l.Rds")) {
  download.file(paste0(data_source, region_name, "/l.Rds"), "l.Rds", mode = "wb")
  download.file(paste0(data_source, region_name, "/rf.Rds"), "rf.Rds", mode = "wb")
  download.file(paste0(data_source, region_name, "/rq.Rds"), "rq.Rds", mode = "wb")
}
```

```{r, echo=FALSE, eval=FALSE}
if(!file.exists("l_nat.Rds")) {
  download.file(url = "https://github.com/npct/pct-bigdata/releases/download/1.6-beta/l_nat.Rds", destfile = "l_nat.Rds", mode = "wb")
  download.file(url = "https://github.com/npct/pct-bigdata/releases/download/1.7-beta/rf_nat.Rds", destfile = "rf_nat.Rds", mode = "wb")
  download.file(url = "https://github.com/npct/pct-bigdata/releases/download/1.7-beta/rq_nat.Rds", destfile = "rq_nat.Rds", mode = "wb")
}
```

```{r, eval=FALSE, echo=FALSE}
# This code takes the national lines and saves by region
l_nat = st_as_sf(readRDS("l_nat.Rds"))
rf_nat = st_as_sf(readRDS("rf_nat.Rds"))
rq_nat = st_as_sf(readRDS("rq_nat.Rds"))
l = l_nat[region,]
l_sel = st_intersects(l_nat, region, sparse = FALSE)[,1]
l = l_nat[l_sel,]
rf = rf_nat[l_sel,]
rq = rq_nat[l_sel,]
plot(l[6])
plot(rf[1], add = T, col = "red")
plot(rq[1], add = T, col = "green")
plot(region[1], col = "white", lwd = 5, add = T)
lfq = list(l, rf, rq)
names(lfq) = c("l", "rf", "rq")
saveRDS(lfq, "../example-data/bristol/lfq.Rds")
```

```{r}
lfq = readRDS("../example-data/bristol/lfq.Rds")
plot(lfq$l[6])
plot(lfq$rf[1], add = T, col = "red")
plot(lfq$rq[1], add = T, col = "green")
plot(region[1], col = "white", lwd = 5, add = T)
```

- OSM data, which can be downloaded using the osmdata R package. We have saved the osm route network in the highways tab.

```{r}
osm_data = readRDS("../example-data/bristol/osm-all-highways.Rds")
ways = osm_data$osm_
```


- Data created by the CyIPT project, which provides data on the current road network from the perspective of cycling.

```{r, echo=FALSE}
if(!file.exists("osm-lines-quietness-full.Rds")) {
  download.file(url = "https://github.com/cyipt/example-data/raw/master/bristol/osm-lines-quietness-full.Rds", destfile = "osm-lines-quietness-full.Rds", mode = "wb")
}

```


```{r}
osm_lines = readRDS("osm-lines-quietness-full.Rds")
```


These can be visualised as follows, with a sample of 5 routes overlaid on a sample of 1000 OSM line elements:

```{r}
plot(osm_lines[sample(x = nrow(osm_lines), size = 1000), 1])
plot(lfq$l[1:5, 6], add = T, col = "black")
plot(lfq$rf[1:5, 6], add = T, col = "red", lwd = 3)
plot(lfq$rq[1:5, 6], add = T, col = "green")
```

We can join the relevant variables from the `rf` and `rq` objects onto `l` for modelling:

```{r}
names(lfq$rf)
rf = transmute(lfq$rf, dist_fast = length / 1000, time_fast = time, busyness_fast = busyness, av_incline_fast = av_incline) 
st_geometry(rf) <- NULL

rq = transmute(lfq$rq, dist_quiet = length / 1000, time_quiet = time, busyness_quiet = busyness, av_incline_quiet = av_incline) 
st_geometry(rq) <- NULL
lfq$l = bind_cols(lfq$l, rf, rq)
l = lfq$l
st_geometry(l) = NULL
```


## Modelling raw cyclist counts

In the propensity to cycle tool, we modelled cycling uptake in terms of `pcycle`, the percentage cycling.

In this section we will estimate the number cycling directly and use inference about the impact of the route network to estimate uptake, using a wide range of variables.

```{r}
names(l)
```

The simplest model of cycling update under this framework would be to estimate the number of cyclists as a linear function of total number travelling:

```{r}
m1 = lm(formula = bicycle ~ all, data = l)
summary(m1)
(rmse1 = sqrt(c(crossprod(m1$residuals)) / nrow(l)))
```

Already, over half of the number of cyclists using roads can be modelled based on the total number of commuters alone, but we're not capturing any of the variability in the proportion cycling.

The impact of adding distance can be isolated in the linear term as follows:

```{r}
m2 = lm(formula = bicycle ~ dist + all, data = l)
summary(m2)
(rmse2 = sqrt(c(crossprod(m2$residuals)) / nrow(l)))
```

Note that the fit has improved, but only very slightly. This is partly because only a linear function of distance is used and it does not interact with `all`. 
Let's simulate that interaction.

So we can fit an interaction term:

```{r}
m3 = lm(formula = bicycle ~ all + dist:all, data = l)
summary(m3)
(rmse3 = sqrt(c(crossprod(m3$residuals)) / nrow(l)))
```


```{r}
plot(l$all, l$bicycle)
points(l$all, m1$fitted.values, col = "red")
points(l$all, m3$fitted.values, col = "grey")
```

There are various issues here. We need to model cycling uptake but that is always a function of `all`. We must add additional variables such as hilliness. Further, we must use non-linear function of some predictor variables such as distance. 

The mission is to improve this fit to account for the impact of infrastructure so we can model cycling uptake when the road network changes.

This is where machine learning can come in.

## Boosted regression trees

Machine learning can provide a way to extract knowledge from the input data.
An implementation is provided by the **xgboost** package:

```{r}
library(xgboost)
set.seed(2017)
l_sub = select(l, bicycle, dist, all)
xgboost(data = as.matrix(l_sub[-1]), label = l_sub$bicycle, nrounds = 5)
train = l_sub %>% 
    sample_frac(size = 0.5)
```

Note that the RMSE has been more than halved by the use of machine learning.
The method's compatibility with the `predict()` function allows us to model uptake of cycling when conditions change.
As a hypothetical example, imagine that all people moved 50%.

Rather than fitting on the complete dataset, we'll build the model on a subset (`train`):

```{R}
m4 = xgboost(data = as.matrix(train[-1]), label = train$bicycle, nrounds = 5, max_depth = 3)
m4_fitted = predict(m4, as.matrix(l_sub[-1]))
plot(l$all, l$bicycle)
points(l$all, m4_fitted, col = "red")
(rmse4 = sqrt(c(crossprod(m4_fitted - l_sub$bicycle)) / nrow(l)))
```

We can query the model results to explore the feature importance:

```{r}
importance_m4 = xgb.importance(model = m4, feature_names = names(l_sub)[-1])
xgb.plot.importance(importance_m4)
```

## A full model

To specify a full model is relatively easy, building on the existing framework:

```{r}
l_full = select(l, bicycle, all, dist, dist_fast, dist_quiet, av_incline_fast, busyness_fast, busyness_quiet)
train = sample_frac(l_full, 0.5)
m5 = xgboost(data = as.matrix(train[-1]), label = train$bicycle, nrounds = 10, max_depth = 5)
importance_m5 = xgb.importance(model = m5, feature_names = names(l_full)[-1])
xgb.plot.importance(importance_m5)
m5_fitted = predict(m5, as.matrix(l_full[-1]))
(rmse5 = sqrt(c(crossprod(m5_fitted - l_full$bicycle)) / nrow(l)))
```

## Fitting to the proportion cycling

We know that `bicycle` is intimately related to `all`. It cannot be higher and is a proportion of it. So instead, we can remove `all` from the equation (the number of people travelling on a route should be independent of their propensity to cycle) and instead to fit to `pcycle`:

```{r}
l_full = select(l, bicycle, all, dist, dist_fast, dist_quiet, av_incline_fast, busyness_fast, busyness_quiet)
train_df = sample_frac(l_full, 0.5)
train = as.matrix(train_df[,-c(1, 2)])
m6 = xgboost(data = train, label = train_df$bicycle / train_df$all, nrounds = 10, max_depth = 5, weight = train_df$all)
importance_m6 = xgb.importance(model = m6, feature_names = names(l_full)[-c(1, 2)])
xgb.plot.importance(importance_m6)
m6_fitted = predict(m6, as.matrix(l_full[-c(1, 2)]))
(rmse6 = sqrt(c(crossprod(m6_fitted * l$all  - l_full$bicycle)) / nrow(l)))
```

Including the relationship between quiet and fast routes:

```{r}
l_full = mutate(l_full, qdf = dist_quiet / dist_fast)
l_full = mutate(l_full, av_busy_quiet = busyness_quiet / dist_quiet, av_busy_fast = busyness_fast / dist_fast) %>% 
  select(-dist, -busyness_fast, -busyness_quiet)

train_df = sample_frac(l_full, 0.5) 
train = as.matrix(train_df[,-c(1, 2)])
m7 = xgboost(data = train, label = train_df$bicycle / train_df$all, nrounds = 10, max_depth = 5, weight = train_df$all)
importance_m7 = xgb.importance(model = m7, feature_names = names(l_full)[-c(1, 2)])
xgb.plot.importance(importance_m7)
m7_fitted = predict(m7, as.matrix(l_full[-c(1, 2)]))
(rmse7 = sqrt(c(crossprod(m7_fitted * l$all  - l_full$bicycle)) / nrow(l)))
```

